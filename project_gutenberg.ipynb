{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_gutenberg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivamParihar/project_gutenberg_character_generation/blob/master/project_gutenberg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_v1rrKty5gW",
        "colab_type": "code",
        "outputId": "552f7ca3-ed09-4bc4-8db6-0410102a5d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4AZsvld0Y-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "faba2051-9de2-41a8-ccd1-34193462d8f2"
      },
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqE1E_a0lM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"/content/gdrive/My Drive/ml_codes/project_gutenberg/new_dataset.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqZMxVWe1Iz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDcF1OQV1mXn",
        "colab_type": "code",
        "outputId": "f1a0d6a2-d455-4416-a035-40fbd4fb72f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nchars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(nchars)\n",
        "print(n_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144321\n",
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2FR1Jkj16tI",
        "colab_type": "code",
        "outputId": "dc038d63-8e58-4f4e-9533-efbaa7eb9f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, nchars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH2ntzne2hig",
        "colab_type": "code",
        "outputId": "52582152-e0d8-46f2-b83b-7ec4f164105c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(dataX[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 24, 17, 32, 36, 21, 34, 1, 25, 10, 1, 20, 31, 39, 30, 1, 36, 24, 21, 1, 34, 17, 18, 18, 25, 36, 9, 24, 31, 28, 21, 0, 0, 17, 28, 25, 19, 21, 1, 39, 17, 35, 1, 18, 21, 23, 25, 30, 30, 25, 30, 23, 1, 36, 31, 1, 23, 21, 36, 1, 38, 21, 34, 41, 1, 36, 25, 34, 21, 20, 1, 31, 22, 1, 35, 25, 36, 36, 25, 30, 23, 1, 18, 41, 1, 24, 21, 34, 1, 35, 25, 35, 36, 21, 34, 1, 31, 30, 1, 36]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1JAaCEs6x3C",
        "colab_type": "code",
        "outputId": "cf73937d-f96e-4189-eeff-d0f6d100cba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(dataY[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMdzQK567SiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS2h95PI7aWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh6IKZ7o7sQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9d0tDrJ8Q0v",
        "colab_type": "code",
        "outputId": "d144e53b-259a-4d8e-9dcd-d1f20effc704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!pip install keras==2.2.5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJ6bkdn8iux",
        "colab_type": "code",
        "outputId": "f262707b-923e-4a2d-e8eb-a967136fbb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.16.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcPEmtiz8Fqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3pr9zof9x5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUCckZwh_kj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8897dc2f-dd32-49d8-f9a5-58b30274ae05"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 144221 samples\n",
            "Epoch 1/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.9772\n",
            "Epoch 00001: loss improved from inf to 2.97703, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 887s 6ms/sample - loss: 2.9770\n",
            "Epoch 2/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.7753\n",
            "Epoch 00002: loss improved from 2.97703 to 2.77529, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 879s 6ms/sample - loss: 2.7753\n",
            "Epoch 3/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.6696\n",
            "Epoch 00003: loss improved from 2.77529 to 2.66956, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 900s 6ms/sample - loss: 2.6696\n",
            "Epoch 4/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.5871\n",
            "Epoch 00004: loss improved from 2.66956 to 2.58697, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 888s 6ms/sample - loss: 2.5870\n",
            "Epoch 5/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.5264\n",
            "Epoch 00005: loss improved from 2.58697 to 2.52626, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 882s 6ms/sample - loss: 2.5263\n",
            "Epoch 6/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.4664\n",
            "Epoch 00006: loss improved from 2.52626 to 2.46639, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 883s 6ms/sample - loss: 2.4664\n",
            "Epoch 7/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.4164\n",
            "Epoch 00007: loss improved from 2.46639 to 2.41631, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 910s 6ms/sample - loss: 2.4163\n",
            "Epoch 8/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.3691\n",
            "Epoch 00008: loss improved from 2.41631 to 2.36909, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 889s 6ms/sample - loss: 2.3691\n",
            "Epoch 9/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.3262\n",
            "Epoch 00009: loss improved from 2.36909 to 2.32627, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 909s 6ms/sample - loss: 2.3263\n",
            "Epoch 10/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.2823\n",
            "Epoch 00010: loss improved from 2.32627 to 2.28226, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 885s 6ms/sample - loss: 2.2823\n",
            "Epoch 11/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.2455\n",
            "Epoch 00011: loss improved from 2.28226 to 2.24558, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 900s 6ms/sample - loss: 2.2456\n",
            "Epoch 12/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.2045\n",
            "Epoch 00012: loss improved from 2.24558 to 2.20464, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 892s 6ms/sample - loss: 2.2046\n",
            "Epoch 13/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.1708\n",
            "Epoch 00013: loss improved from 2.20464 to 2.17086, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 907s 6ms/sample - loss: 2.1709\n",
            "Epoch 14/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.1346\n",
            "Epoch 00014: loss improved from 2.17086 to 2.13478, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 866s 6ms/sample - loss: 2.1348\n",
            "Epoch 15/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.1002\n",
            "Epoch 00015: loss improved from 2.13478 to 2.10018, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 866s 6ms/sample - loss: 2.1002\n",
            "Epoch 16/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.0690\n",
            "Epoch 00016: loss improved from 2.10018 to 2.06902, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 895s 6ms/sample - loss: 2.0690\n",
            "Epoch 17/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.0393\n",
            "Epoch 00017: loss improved from 2.06902 to 2.03940, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 897s 6ms/sample - loss: 2.0394\n",
            "Epoch 18/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 2.0090\n",
            "Epoch 00018: loss improved from 2.03940 to 2.00899, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 896s 6ms/sample - loss: 2.0090\n",
            "Epoch 19/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 1.9788\n",
            "Epoch 00019: loss improved from 2.00899 to 1.97895, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 892s 6ms/sample - loss: 1.9789\n",
            "Epoch 20/20\n",
            "144128/144221 [============================>.] - ETA: 0s - loss: 1.9579\n",
            "Epoch 00020: loss improved from 1.97895 to 1.95774, saving model to /content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\n",
            "144221/144221 [==============================] - 866s 6ms/sample - loss: 1.9577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff78fff3908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7EslFwynvR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5e1dda7c-db5a-46bf-aceb-f0637d1d4d0c"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# load the network weights\n",
        "filename = \"/content/gdrive/My Drive/ml_codes/project_gutenberg/weights_improvement.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCuw1vPVojTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpv5u759m9KJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "5f3a1b79-6b48-4736-a7d9-0737670efff5"
      },
      "source": [
        "import sys\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(''.join([int_to_char[value] for value in pattern]))\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "t used up.'\n",
            "\n",
            "'but what happens when you come to the beginning again?' alice ventured\n",
            "to ask.\n",
            "\n",
            "'suppo\n",
            "n, and that ' said the monke, shthing to the jury. and the horp ofs oi ae in her hoed an ohce, and the cotmdus sasd thin she was sollling to fnr the was to ald to the kat has hasden teen the was so aedin in the hadd.\n",
            "'nh whuh the qerten tf thin ' \n",
            "'tha sar of the dorsonse ' said the monke, shthing to alice an in ouoert no an sfeer. ''than sou dould be io deleed to thu woine you dan't tiln ' said alice, 'and thet so lete heve thet lo beter ai afriee ' \n",
            "'i whnh y uhe kart ri gare to tou then ' sail alice, and she hurph of the word whu would be ailngd to the karth thse the whst on begngng, and saed to the katthen in the horg, and the whrt ondel litele the had noet war to sar the qoeen saed to the katthrn in the court, and taede  she fatt round the saie the sar of thing she whst sadd to the katter. 'no she sert woud wou'd nott ' shought alice, 'i wou'o  aall the horn of theng sheng so be a lood tian!' \n",
            "'i dan tou d dan hi toehe,' said the konge, sn a sertee, \n",
            "and she gorph wo see whnte gar\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}